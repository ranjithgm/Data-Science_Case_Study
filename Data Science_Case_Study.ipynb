{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Paper\n",
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Instructions</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Allowed time - 1 hour\n",
    "* All tasks are equally important.\n",
    "* Submit only Jupyter notebook with your results\n",
    "* Multiple Jupyter notebooks submission not allowed\n",
    "* Comments the code whenever possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Section 1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T15:21:00.469891Z",
     "start_time": "2019-04-20T15:21:00.466296Z"
    }
   },
   "source": [
    "<b>Task 1</b>\n",
    "<br>\n",
    "There are two Pandas series $S_a = [1,2,3,4,5]$ and $S_b = [4,5,6,7,8]$. \n",
    "<br>Find elements in $S_a$ that are not in $S_b$ using one line code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "unique(S_a [! S_a %in% S_b])\n",
    "\n",
    "Answer\n",
    "[1] 1 2 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 2 </b>\n",
    "<br>\n",
    "Generate 1000 samples following normal (Gaussian) distribution with mean 1 and variance 5.\n",
    "<br> Find the list of top 20 largest values from the generated samples in absolute term.\n",
    "<br> Fit kernel density to the generated samples and plot with histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "\n",
    "x <- seq(1, 1000, by = 1)\n",
    "y <- dnorm(x, mean = 1, var(5)) \n",
    "\n",
    "Answer\n",
    "x - Generates 1000 samples\n",
    "y - Normal Guassian Distribution\n",
    "            \n",
    "tail(sort(x),20) \n",
    "\n",
    "Answer\n",
    "20 largest values\n",
    "[1]  981  982  983  984  985  986  987  988  989  990  991  992  993  994  995  996  997  998\n",
    "[19]  999 1000\n",
    "            \n",
    "density(x, kernel = c(\"guassian\", n = 1000) \n",
    "\n",
    "Answer\n",
    "Fit the kernel density\n",
    "\n",
    "n        <- 1000\n",
    "mean     <- 1\n",
    "var       <- 5\n",
    "binwidth <- 2\n",
    "height <- rnorm(n, mean, var)\n",
    "\n",
    "\n",
    "qqplot(height, geom = \"histogram\", breaks = seq(130, 200, binwidth), \n",
    "      colour = I(\"black\"), fill = I(\"white\"),\n",
    "      xlab = \"Height (cm)\", ylab = \"Count\") \n",
    "        \n",
    "Answer\n",
    "Generates the histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task 3 </b><br>\n",
    "Create random Pandas dataframe of size 50x26 with column names 'A', 'B', ..., 'Z'. <br>\n",
    "Reorder the columns in the format ['A', 'Z', 'B', 'Y', 'C', 'X', 'D', ...] and display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "data.frame(replicate(26,sample(letters,50,rep=TRUE))) -> dataframe_new  \n",
    "\n",
    "Answer\n",
    "50x26 dataframe with alphatets\n",
    "y  s  d  p  e  n  t  u  c   r   c   j   z   z   p   s   p   w   y   j   i   c   b   o   a\n",
    "2   n  f  u  p  t  c  c  f  c   v   l   x   p   j   l   f   q   z   c   x   g   e   g   b   w\n",
    "3   h  \n",
    "\n",
    "library(plyr)\n",
    "arrange(dataframe_new,desc(z),a)\n",
    "\n",
    "Answer\n",
    "a  z  b y  c  x  d  w  e  v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T15:35:40.289636Z",
     "start_time": "2019-04-20T15:35:40.285714Z"
    }
   },
   "source": [
    "<b>Task 4</b><br>\n",
    "Write sample function to do summation of given multiple arguments.<br>\n",
    "e.g.<br>\n",
    "sum_func(2,3) = 5 <br>\n",
    "sum_func(1,2,3,4,5) = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here \n",
    "aggregate(sum_func(2,3) = 5,sum_func(1,2,3,4,5) = 15, by = list(unique.values = values$value))\n",
    "\n",
    "Answer\n",
    "sum_func(1,2,3,4,5) = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T15:38:20.010978Z",
     "start_time": "2019-04-20T15:38:20.008718Z"
    }
   },
   "source": [
    "### <u>Section 2</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T15:42:51.183509Z",
     "start_time": "2019-04-20T15:42:51.172964Z"
    }
   },
   "source": [
    "<b> Task 5 </b> <br>\n",
    "There are time-series datasets given of two subjects 'AA' and 'AL'. The datasets are given in two formats - \n",
    "1. CSV - There are two files corresponding to each subjects; rawData\\*.csv and cueResponseData\\*.csv. <br>The rawDataAA contains filtered time-series brain activity data from subject 'AA' where columns correspond to the list of recorded channels. <br>The cueResponseDataAA contains information of cue start time, class variables - label_train and true_label for each trials. Each trials are classified into two classes<br><br>\n",
    "2. Pickle file - It contains tuple (rawData, cueResponseData). The information about rawData and cueResponseData are same as above.\n",
    "<br><br> Both datasets are recorded at <b>100Hz</b>, i.e., it contains 100 samples at each second of observations.\n",
    "<br> Load the data of both subjects from any formats as your convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here \n",
    "cueResponse <- read.csv(\"C:/Users/Ranjit/Desktop/Case_study/cueResponseDataAA.csv\")\n",
    "cueResponse1 <- read.csv(\"C:/Users/Ranjit/Desktop/Case_study/cueResponseDataAL.csv\")\n",
    "View(cueResponse) \n",
    "\n",
    "Answer\n",
    "Displays the csv files\n",
    "4748           1          1\n",
    "2     5282           1          1\n",
    "3     6954           2          2\n",
    "4     8621           1          1\n",
    "5     9180           1      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 6 </b> <br>\n",
    "For each trial extract the samples from 0.5s to 2.5s from the filtered raw data after the cue corresponding to trial is presented for each individual subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here \n",
    "dataframe1 = data.frame(a = 0.5:2.5)\n",
    "new_dataframe = subset(dataframe1, a %in% 0.5:2.5)\n",
    "new_dataframe\n",
    "\n",
    "Answer\n",
    "  a\n",
    "1 0.5\n",
    "2 1.5\n",
    "3 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 7 </b> <br>\n",
    "For each subjects, generate a 3D tensor in the form (number of trials - number of channels - number of time samples). From the 3D tensor data, select the following channels C3, C4 and Cz for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "library(tensorr)\n",
    "\n",
    "num_trials <- c(1,n)\n",
    "num_channels <- c(1,n)\n",
    "num_time_samples <- c(1,n)\n",
    "\n",
    "x <- dtensor(num_trials, num_channels, num_time_samples)\n",
    "x\n",
    "\n",
    "Answer\n",
    "3D tensor generated and the channels are selected to process further\n",
    "\n",
    "x\n",
    "   [1]    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   18\n",
    "  [19]   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35   36\n",
    "  [37]   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54\n",
    "  [55]   55   56   57   58 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 8 </b> <br>\n",
    "<i>Feature extraction:</i> Extract \"Log(Variance)\" of each channels C3, C4 and Cz from the preprocessed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "apply(df[c(\"c3\", \"c4\", \"cz\")], 1, var)\n",
    "\n",
    "Answer\n",
    "variance 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 9 </b> <br>\n",
    "<i>Classification:</i> Using the column 'label_train' from the 'cueResponseData', apply 10-fold cross validation to predict classes using models LDA (Linear Discriminant Analysis) and SVC (Support Vector Classification). Report classification accuracies for each test sets using subjects individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# load dataset\n",
    "\n",
    "dataframe <- read.csv(\"C:/Users/Ranjit/Desktop/Case_study/cueResponseDataAA.csv\")\n",
    "\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "Running the example provides algorithm mean accuracy below\n",
    "\n",
    "LDA: 0.773462 \n",
    "SVM: 0.651025 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Task 10 </b> <br>\n",
    "<i> Prediction: </i> Fit the classification algorithms LDA and SVC using the response from 'label_train' and predict the missing response values. Using the true label from the column 'true_label', report classification accuracy, precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here\n",
    "\n",
    "LDA\n",
    "\n",
    "sublda=lda(cueResponse~.,data = label_train)\n",
    "sublda\n",
    "plot(sublda, dimen = 1, type = \"b\")\n",
    "lda.pred=predict(sublda, newdata = label_test)   \n",
    "\n",
    "Answer\n",
    "         pred.1 pred.0\n",
    " actual.1     27    185\n",
    " actual.0     30   1258\n",
    "\n",
    "library(\"hmeasure\")\n",
    "\n",
    "class.lda=lda.pred$class\n",
    "true.class<-testdata[,1]\n",
    "lda.counts <- misclassCounts(class.lda,true.class)\n",
    "lda.counts$conf.matrix ->metrics1\n",
    "\n",
    "print(lda.counts$metrics,digits=3)\n",
    "\n",
    "Answer\n",
    "\n",
    "      ER  Sens  Spec Precision Recall   TPR   \n",
    "\t 1 0.143 0.127 0.977     0.474  0.127 0.127 0.0233 \n",
    "\n",
    "Accuracy = 1 - Error rate\n",
    "\n",
    "\n",
    "ggplot(clf, dat[label_train,geom_histogram()]) + geom_point()\n",
    "ggplot(metrics1, dat[label_train,geom_histogram()]) + geom_point()\n",
    "\n",
    "When plotted, the accuracy, sensitivity, and specificity for various threshold values, the three lines intersect at a particular point. The threshold corresponding to this point indicates the optimum threshold for the model\n",
    "\n",
    "SVC\n",
    "\n",
    "library(\"scikit\")\n",
    "\n",
    "clf = SVC(kernel='linear', C= 1)\n",
    "clf.fit(label_test, label_train)\n",
    "prediction = clf.predict(label_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print 'Accuracy:', accuracy_score(label_train, prediction)\n",
    "print 'F1 score:', f1_score(label_train, prediction)\n",
    "print 'Recall:', recall_score(label_train, prediction)\n",
    "print 'Precision:', precision_score(label_train, prediction)\n",
    "print '\\n clasification report:\\n', classification_report(label_train,prediction)\n",
    "print '\\n confussion matrix:\\n',confusion_matrix(label_train, prediction)\n",
    "\n",
    "Answer\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       0.65      1.00      0.79        17\n",
    "          1       0.57      0.75      0.65        16\n",
    "\n",
    "\n",
    "ggplot(clf, dat[label_train,geom_histogram()]) + geom_point()\n",
    "ggplot(Accuracy,Recall,Precision, dat[label_train,geom_histogram()]) + geom_point()\n",
    "\n",
    "\n",
    "When plotted, the accuracy, sensitivity, and specificity for various threshold values, the three lines intersect at a particular point. The threshold corresponding to this point indicates the optimum threshold for the model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
